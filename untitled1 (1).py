# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q4gnZu6c6T50zx65lUAVLHnKJn8oZipO
"""

# STEP 1: تثبيت الحزم المطلوبة
!apt-get install -y tesseract-ocr tesseract-ocr-ara
!pip install -q pytesseract Pillow requests
# llama-cpp لتشغيل نموذج Mistral محلياً
!CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python==0.2.44  --no-cache-dir

# STEP 2: تحميل نموذج Mistral من Hugging Face مباشرة (Q4_0)
import os

model_url = "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_0.gguf"
model_path = "mistral.Q4_0.gguf"

if not os.path.exists(model_path):
    print("⏬ Downloading Mistral model (Q4_0)...")
    import urllib.request
    urllib.request.urlretrieve(model_url, model_path)
    print("✅ Model downloaded!")
else:
    print("✔ Model already exists.")

# STEP 3: رفع صورة الفاتورة
from google.colab import files
uploaded = files.upload()
image_path = next(iter(uploaded))

# STEP 4: تشغيل OCR على الفاتورة
from PIL import Image
import pytesseract

img = Image.open(image_path)
text = pytesseract.image_to_string(img, lang='eng+ara')

print("📄 نص الفاتورة:\n")
print(text)

# STEP 5: تشغيل نموذج Mistral على النص
from llama_cpp import Llama

llm = Llama(model_path="mistral.Q4_0.gguf", n_ctx=2048)

# تجهيز البرومبت
prompt = f"""
[INST]
Analyze the following invoice.
Extract all expenses with amounts, and classify them into categories like:
food, groceries, transport, entertainment, utilities and other.
Return a JSON object and do not give any comment or explanation.

Invoice:
{text}
[/INST]
"""

# تشغيل النموذج
response = llm(prompt, max_tokens=512, stop=["</s>"])

# عرض النتيجة
output = response["choices"][0]["text"]
print("\n📊 المصاريف المصنفة:\n")
print(output)

"""#### Attempting to connect directly to Firebase
unsuccessful 😅
"""

# STEP 1: Install Required Packages
!pip install -q llama-cpp-python==0.2.44 requests

# STEP 2: Load Mistral Model
from llama_cpp import Llama
import requests
import time

# Load the Mistral model (must be downloaded in advance)
llm = Llama(model_path="mistral-7b-instruct-v0.1.Q4_0.gguf", n_ctx=2048)

# STEP 3: Set Firebase Database URL
FIREBASE_URL = "https://YOUR_PROJECT_ID.firebaseio.com"  # <-- Replace with your real Firebase Realtime DB URL

# Optional: If using authentication, add auth token
FIREBASE_AUTH = ""  # leave blank for open DBs

# Helper to build the full URL to an endpoint in Firebase
def firebase_url(path):
    url = f"{FIREBASE_URL}/{path}.json"
    if FIREBASE_AUTH:
        url += f"?auth={FIREBASE_AUTH}"
    return url

# STEP 4: Read the latest input from Firebase

def get_latest_prompt():
    try:
        res = requests.get(firebase_url("prompts"))
        data = res.json()
        if not data:
            return None, None
        # Get the last prompt entry
        sorted_items = sorted(data.items(), key=lambda x: x[1].get("timestamp", 0), reverse=True)
        prompt_id, prompt_data = sorted_items[0]
        return prompt_id, prompt_data["text"]
    except Exception as e:
        print("Error reading Firebase:", e)
        return None, None

# STEP 5: Send prompt to model and get response

def run_model(prompt_text):
    formatted_prompt = f"""
    [INST] {prompt_text} [/INST]
    """
    response = llm(formatted_prompt, max_tokens=512, stop=["</s>"])
    return response["choices"][0]["text"].strip()

# STEP 6: Write the result back to Firebase

def save_response(prompt_id, response_text):
    data = {"response": response_text, "timestamp": int(time.time())}
    res = requests.patch(firebase_url(f"prompts/{prompt_id}"), json=data)
    return res.status_code == 200

# STEP 7: Full process: check Firebase ➜ run model ➜ update Firebase

prompt_id, prompt_text = get_latest_prompt()
if prompt_text:
    print("✅ Got prompt:", prompt_text)
    answer = run_model(prompt_text)
    print("🤖 Model reply:", answer)
    success = save_response(prompt_id, answer)
    if success:
        print("📤 Response saved to Firebase.")
    else:
        print("❌ Failed to save response.")
else:
    print("📭 No prompts found in Firebase.")

