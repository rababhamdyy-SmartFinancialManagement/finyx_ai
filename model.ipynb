{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "53ffcde7-3689-480b-b8fc-a276922b702a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bZsfBuZDeCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c95923-1e7d-4ff8-c959-9d8db8bc0090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.3.19 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 32, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Llama-3.1` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Llama-3 renders multi turn conversations like below:\n",
        "\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "I'm great thanks!<|eot_id|>\n",
        "```\n",
        "\n",
        "We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3` and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "# Load your business financial JSONL file\n",
        "data = []\n",
        "with open('business_dataset.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "# Create a function that works with business financial examples\n",
        "def format_business_example(item):\n",
        "    # Prepare a conversation format with the business financial data\n",
        "    convo = [\n",
        "        {'role': 'user', 'content': item['business_financial_summary']},\n",
        "        {'role': 'assistant', 'content': (\n",
        "            f\"Profitability Analysis: {item['profitability_analysis']}\\n\\n\"\n",
        "            f\"Cash Flow Recommendations: {item['cash_flow_recommendations']}\\n\\n\"\n",
        "            f\"Expense Optimization Strategies:\\n{format_expense_optimization(item['expense_optimization'])}\\n\\n\"\n",
        "            f\"Investment Opportunities: {item['investment_opportunities']}\\n\\n\"\n",
        "            f\"Risk Assessment: {item['risk_assessment']}\"\n",
        "        )}\n",
        "    ]\n",
        "\n",
        "    # Apply tokenizer template to create formatted text\n",
        "    formatted_text = tokenizer.apply_chat_template(\n",
        "        convo,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=False\n",
        "    )\n",
        "\n",
        "    return {'text': formatted_text, 'conversations': convo}\n",
        "\n",
        "# Helper function to format the expense optimization (handles both dict and string)\n",
        "def format_expense_optimization(expense_data):\n",
        "    # Check if expense_optimization is a string or a dictionary\n",
        "    if isinstance(expense_data, str):\n",
        "        # If it's already a string, return it directly\n",
        "        return expense_data\n",
        "    elif isinstance(expense_data, dict):\n",
        "        # If it's a dictionary, format it nicely\n",
        "        formatted_text = \"\"\n",
        "        for category, recommendation in expense_data.items():\n",
        "            formatted_text += f\"- {category}: {recommendation}\\n\"\n",
        "        return formatted_text\n",
        "    else:\n",
        "        # Fallback for any other data type\n",
        "        return str(expense_data)\n",
        "\n",
        "# Process all business financial examples\n",
        "formatted_business_data = [format_business_example(item) for item in data]\n",
        "\n",
        "# Create dataset with both text and conversations\n",
        "train_data = Dataset.from_list(formatted_business_data)\n",
        "\n",
        "# Alternatively, if you only want the 'text' field:\n",
        "# business_train_data = Dataset.from_dict({'text': [x['text'] for x in formatted_business_data]})\n",
        "\n",
        "# Preview the first example to verify formatting\n",
        "print(\"Sample formatted business financial data:\")\n",
        "print(formatted_business_data[0]['text'][:500] + \"...\")  # Print first 500 chars\n",
        "\n",
        "# Save the processed dataset if needed\n",
        "# business_train_data.save_to_disk(\"processed_business_financial_dataset\")"
      ],
      "metadata": {
        "id": "3hkVuX0fnldh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3c3d5e-609e-434c-e661-7518ae863960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample formatted business financial data:\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "The company generated a total revenue of $520,914.02 in January 1960. Employee salaries constitute the largest expense at $128,625.48, followed by raw materials at $91,696.32. Other significant expenses include taxes ($45,779.57), marketing ($33,529.62), and transfer money ($40,064.26). After accounting for all expenses, ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XjeVBeYBoVIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look at how the conversations are structured for item 5:"
      ],
      "metadata": {
        "id": "ndDUB23CGAC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we see how the chat template transformed these conversations.\n",
        "\n",
        "**[Notice]** Llama 3.1 Instruct's default chat template default adds `\"Cutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\"`, so do not be alarmed!"
      ],
      "metadata": {
        "id": "GfzTdMtvGE6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[5][\"conversations\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFzmplrEy9I",
        "outputId": "7afec731-049d-459f-924c-4c10b3407232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': \"The company's financial data for June 1960 shows a total revenue of $456,647.43 and profits of $23,353.07. Significant expenses include employee salaries ($169,930.94), raw materials ($94,440.34), and taxes ($50,920.52). Loan payments are $27,822.76. Other expenses such as utilities, rent, marketing, insurance, office supplies, and maintenance also contribute to the overall cost structure. A transfer of $37,152.90 is also noted. The profit margin, calculated as (Profit / Total Revenue) * 100, is approximately 5.11%.\",\n",
              "  'role': 'user'},\n",
              " {'content': 'Profitability Analysis: The profitability analysis reveals a relatively low profit margin of 5.11%. While revenue is substantial, the high cost of employee salaries and raw materials significantly impacts the bottom line. Revenue growth trends are not available from this single data point, but monitoring these trends over time is crucial. Expense management, particularly in the areas of salaries and raw materials, needs careful attention. A cost-benefit analysis of marketing spend ($33,730.93) should be conducted to ensure it is effectively driving revenue. The impact of taxes ($50,920.52) is also significant and should be considered in long-term financial planning.\\n\\nCash Flow Recommendations: To improve cash flow, several strategies can be implemented. Firstly, negotiate extended payment terms with raw material suppliers to delay cash outflows. Secondly, explore options for more efficient inventory management to reduce the amount of capital tied up in raw materials. Thirdly, review the loan terms to potentially refinance at a lower interest rate or extend the repayment period, thereby reducing the monthly loan payment. Fourthly, optimize the timing of revenue collection by offering incentives for early payments or implementing stricter credit control measures. Finally, consider establishing a cash reserve to buffer against unexpected expenses or revenue shortfalls.\\n\\nExpense Optimization Strategies:\\n- Employee_Salaries: Conduct a salary benchmarking exercise to ensure compensation is competitive but not excessive. Explore opportunities for improving employee productivity through training or process improvements to justify the salary expense. Consider implementing performance-based incentives to align employee goals with company profitability.\\n- Raw_Materials: Negotiate volume discounts with suppliers or explore alternative, more cost-effective raw material sources. Implement a robust inventory management system to minimize waste and reduce storage costs. Analyze the raw material usage to identify potential areas for optimization or substitution.\\n- Marketing: Evaluate the effectiveness of current marketing campaigns and channels. Focus on strategies with the highest return on investment (ROI). Consider shifting towards more cost-effective digital marketing strategies or negotiating better rates with existing marketing vendors.\\n- Utilities: Implement energy-saving measures to reduce utility consumption. Conduct an energy audit to identify areas for improvement. Negotiate better rates with utility providers.\\n- Office_Supplies: Implement a policy to reduce waste and encourage responsible use of office supplies. Negotiate bulk discounts with suppliers.\\n- Maintenance: Implement a preventative maintenance program to reduce the likelihood of costly repairs. Negotiate service contracts with maintenance providers.\\n\\n\\nInvestment Opportunities: Based on the current financial data, potential investment opportunities could include: 1) Investing in technology or equipment that improves operational efficiency and reduces raw material waste. 2) Expanding into new markets or product lines to diversify revenue streams and reduce reliance on existing products. 3) Investing in employee training and development to improve productivity and reduce employee turnover. 4) Exploring strategic partnerships or acquisitions to gain access to new technologies, markets, or resources. A thorough market analysis and financial modeling should be conducted before making any investment decisions.\\n\\nRisk Assessment: The company faces several financial risks. High reliance on a single revenue stream makes it vulnerable to market fluctuations. The significant expense related to raw materials exposes the company to price volatility. The loan payment represents a fixed financial obligation that could strain cash flow during periods of low revenue. The relatively low profit margin indicates limited financial flexibility. To mitigate these risks, the company should diversify its revenue streams, hedge against raw material price fluctuations, maintain a healthy cash reserve, and continuously monitor its financial performance.',\n",
              "  'role': 'assistant'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[5][\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "vhXv0xFMGNKE",
        "outputId": "e03d564e-0334-412f-cba0-8b9ead6d6988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThe company's financial data for June 1960 shows a total revenue of $456,647.43 and profits of $23,353.07. Significant expenses include employee salaries ($169,930.94), raw materials ($94,440.34), and taxes ($50,920.52). Loan payments are $27,822.76. Other expenses such as utilities, rent, marketing, insurance, office supplies, and maintenance also contribute to the overall cost structure. A transfer of $37,152.90 is also noted. The profit margin, calculated as (Profit / Total Revenue) * 100, is approximately 5.11%.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nProfitability Analysis: The profitability analysis reveals a relatively low profit margin of 5.11%. While revenue is substantial, the high cost of employee salaries and raw materials significantly impacts the bottom line. Revenue growth trends are not available from this single data point, but monitoring these trends over time is crucial. Expense management, particularly in the areas of salaries and raw materials, needs careful attention. A cost-benefit analysis of marketing spend ($33,730.93) should be conducted to ensure it is effectively driving revenue. The impact of taxes ($50,920.52) is also significant and should be considered in long-term financial planning.\\n\\nCash Flow Recommendations: To improve cash flow, several strategies can be implemented. Firstly, negotiate extended payment terms with raw material suppliers to delay cash outflows. Secondly, explore options for more efficient inventory management to reduce the amount of capital tied up in raw materials. Thirdly, review the loan terms to potentially refinance at a lower interest rate or extend the repayment period, thereby reducing the monthly loan payment. Fourthly, optimize the timing of revenue collection by offering incentives for early payments or implementing stricter credit control measures. Finally, consider establishing a cash reserve to buffer against unexpected expenses or revenue shortfalls.\\n\\nExpense Optimization Strategies:\\n- Employee_Salaries: Conduct a salary benchmarking exercise to ensure compensation is competitive but not excessive. Explore opportunities for improving employee productivity through training or process improvements to justify the salary expense. Consider implementing performance-based incentives to align employee goals with company profitability.\\n- Raw_Materials: Negotiate volume discounts with suppliers or explore alternative, more cost-effective raw material sources. Implement a robust inventory management system to minimize waste and reduce storage costs. Analyze the raw material usage to identify potential areas for optimization or substitution.\\n- Marketing: Evaluate the effectiveness of current marketing campaigns and channels. Focus on strategies with the highest return on investment (ROI). Consider shifting towards more cost-effective digital marketing strategies or negotiating better rates with existing marketing vendors.\\n- Utilities: Implement energy-saving measures to reduce utility consumption. Conduct an energy audit to identify areas for improvement. Negotiate better rates with utility providers.\\n- Office_Supplies: Implement a policy to reduce waste and encourage responsible use of office supplies. Negotiate bulk discounts with suppliers.\\n- Maintenance: Implement a preventative maintenance program to reduce the likelihood of costly repairs. Negotiate service contracts with maintenance providers.\\n\\n\\nInvestment Opportunities: Based on the current financial data, potential investment opportunities could include: 1) Investing in technology or equipment that improves operational efficiency and reduces raw material waste. 2) Expanding into new markets or product lines to diversify revenue streams and reduce reliance on existing products. 3) Investing in employee training and development to improve productivity and reduce employee turnover. 4) Exploring strategic partnerships or acquisitions to gain access to new technologies, markets, or resources. A thorough market analysis and financial modeling should be conducted before making any investment decisions.\\n\\nRisk Assessment: The company faces several financial risks. High reliance on a single revenue stream makes it vulnerable to market fluctuations. The significant expense related to raw materials exposes the company to price volatility. The loan payment represents a fixed financial obligation that could strain cash flow during periods of low revenue. The relatively low profit margin indicates limited financial flexibility. To mitigate these risks, the company should diversify its revenue streams, hedge against raw material price fluctuations, maintain a healthy cash reserve, and continuously monitor its financial performance.<|eot_id|>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "dcac68802f1d476f982a30928ca197c5",
            "ffdb8ccef9304d99ac9f1d82f7e05f5b",
            "aeda3965b55e4d698a36a20ed29fbf66",
            "7d21fc25b2134c22892ad43fbefc59c5",
            "feeea8eb37ee402b8bff60a8412367e8",
            "9e35aae97faf461a9186e8963a195236",
            "899d233c052c49dea9b5a55d727762b6",
            "2960fd59a3e140c382425b5a8fd46942",
            "44faf1fa2b8e4c689ebef910e85fc72f",
            "b8789041c4834dc68f3f442f10ef4d7d",
            "dab3bf6981704269886989739e31727b"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "71a39d26-670f-41da-ac37-998d5a2d49d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/780 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcac68802f1d476f982a30928ca197c5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "from datasets import Dataset\n",
        "\n",
        "# Convert the train_data list to a Hugging Face Dataset\n",
        "train_data = Dataset.from_list(train_data)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_data,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"wandb\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
      ],
      "metadata": {
        "id": "C_sGp5XlG6dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3abe868cc2e146f68f0388bebeeb3909",
            "63e8a456d10549279c1f0dc964c1e63b",
            "11f2f5c0e43b4d81ac150b24c5760d34",
            "6bfa8112bee94c39bba066fdac853277",
            "e4e5c2a23b834d5e8845d6ad249139d4",
            "f28be94b4dc74397abba929360a9d744",
            "dbde1d2ee54f45db85206a22ed4c8f60",
            "29dee39fd0d44d19b88a1270e272662c",
            "49894d0e5f1b4a01b9501c7c63763fcf",
            "b60b4d61133f4ddaa8a3f8862badb0f1",
            "2eb1122f1e0f4b59baa1b2fca658b4bd"
          ]
        },
        "id": "juQiExuBG5Bt",
        "outputId": "8c03fe81-6129-41b3-dea5-5578e98031f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/780 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3abe868cc2e146f68f0388bebeeb3909"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We verify masking is actually done:"
      ],
      "metadata": {
        "id": "Dv1NBUozV78l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "LtsMVtlkUhja",
        "outputId": "6c3f908a-923e-4fc3-9376-e5089cfa3825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nThe company's financial data for June 1960 shows a total revenue of $456,647.43 and profits of $23,353.07. Significant expenses include employee salaries ($169,930.94), raw materials ($94,440.34), and taxes ($50,920.52). Loan payments are $27,822.76. Other expenses such as utilities, rent, marketing, insurance, office supplies, and maintenance also contribute to the overall cost structure. A transfer of $37,152.90 is also noted. The profit margin, calculated as (Profit / Total Revenue) * 100, is approximately 5.11%.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nProfitability Analysis: The profitability analysis reveals a relatively low profit margin of 5.11%. While revenue is substantial, the high cost of employee salaries and raw materials significantly impacts the bottom line. Revenue growth trends are not available from this single data point, but monitoring these trends over time is crucial. Expense management, particularly in the areas of salaries and raw materials, needs careful attention. A cost-benefit analysis of marketing spend ($33,730.93) should be conducted to ensure it is effectively driving revenue. The impact of taxes ($50,920.52) is also significant and should be considered in long-term financial planning.\\n\\nCash Flow Recommendations: To improve cash flow, several strategies can be implemented. Firstly, negotiate extended payment terms with raw material suppliers to delay cash outflows. Secondly, explore options for more efficient inventory management to reduce the amount of capital tied up in raw materials. Thirdly, review the loan terms to potentially refinance at a lower interest rate or extend the repayment period, thereby reducing the monthly loan payment. Fourthly, optimize the timing of revenue collection by offering incentives for early payments or implementing stricter credit control measures. Finally, consider establishing a cash reserve to buffer against unexpected expenses or revenue shortfalls.\\n\\nExpense Optimization Strategies:\\n- Employee_Salaries: Conduct a salary benchmarking exercise to ensure compensation is competitive but not excessive. Explore opportunities for improving employee productivity through training or process improvements to justify the salary expense. Consider implementing performance-based incentives to align employee goals with company profitability.\\n- Raw_Materials: Negotiate volume discounts with suppliers or explore alternative, more cost-effective raw material sources. Implement a robust inventory management system to minimize waste and reduce storage costs. Analyze the raw material usage to identify potential areas for optimization or substitution.\\n- Marketing: Evaluate the effectiveness of current marketing campaigns and channels. Focus on strategies with the highest return on investment (ROI). Consider shifting towards more cost-effective digital marketing strategies or negotiating better rates with existing marketing vendors.\\n- Utilities: Implement energy-saving measures to reduce utility consumption. Conduct an energy audit to identify areas for improvement. Negotiate better rates with utility providers.\\n- Office_Supplies: Implement a policy to reduce waste and encourage responsible use of office supplies. Negotiate bulk discounts with suppliers.\\n- Maintenance: Implement a preventative maintenance program to reduce the likelihood of costly repairs. Negotiate service contracts with maintenance providers.\\n\\n\\nInvestment Opportunities: Based on the current financial data, potential investment opportunities could include: 1) Investing in technology or equipment that improves operational efficiency and reduces raw material waste. 2) Expanding into new markets or product lines to diversify revenue streams and reduce reliance on existing products. 3) Investing in employee training and development to improve productivity and reduce employee turnover. 4) Exploring strategic partnerships or acquisitions to gain access to new technologies, markets, or resources. A thorough market analysis and financial modeling should be conducted before making any investment decisions.\\n\\nRisk Assessment: The company faces several financial risks. High reliance on a single revenue stream makes it vulnerable to market fluctuations. The significant expense related to raw materials exposes the company to price volatility. The loan payment represents a fixed financial obligation that could strain cash flow during periods of low revenue. The relatively low profit margin indicates limited financial flexibility. To mitigate these risks, the company should diversify its revenue streams, hedge against raw material price fluctuations, maintain a healthy cash reserve, and continuously monitor its financial performance.<|eot_id|>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "_rD6fl8EUxnG",
        "outputId": "c5f45aae-8ab6-43db-8266-2d7d9eee4db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                                                                                                                        Profitability Analysis: The profitability analysis reveals a relatively low profit margin of 5.11%. While revenue is substantial, the high cost of employee salaries and raw materials significantly impacts the bottom line. Revenue growth trends are not available from this single data point, but monitoring these trends over time is crucial. Expense management, particularly in the areas of salaries and raw materials, needs careful attention. A cost-benefit analysis of marketing spend ($33,730.93) should be conducted to ensure it is effectively driving revenue. The impact of taxes ($50,920.52) is also significant and should be considered in long-term financial planning.\\n\\nCash Flow Recommendations: To improve cash flow, several strategies can be implemented. Firstly, negotiate extended payment terms with raw material suppliers to delay cash outflows. Secondly, explore options for more efficient inventory management to reduce the amount of capital tied up in raw materials. Thirdly, review the loan terms to potentially refinance at a lower interest rate or extend the repayment period, thereby reducing the monthly loan payment. Fourthly, optimize the timing of revenue collection by offering incentives for early payments or implementing stricter credit control measures. Finally, consider establishing a cash reserve to buffer against unexpected expenses or revenue shortfalls.\\n\\nExpense Optimization Strategies:\\n- Employee_Salaries: Conduct a salary benchmarking exercise to ensure compensation is competitive but not excessive. Explore opportunities for improving employee productivity through training or process improvements to justify the salary expense. Consider implementing performance-based incentives to align employee goals with company profitability.\\n- Raw_Materials: Negotiate volume discounts with suppliers or explore alternative, more cost-effective raw material sources. Implement a robust inventory management system to minimize waste and reduce storage costs. Analyze the raw material usage to identify potential areas for optimization or substitution.\\n- Marketing: Evaluate the effectiveness of current marketing campaigns and channels. Focus on strategies with the highest return on investment (ROI). Consider shifting towards more cost-effective digital marketing strategies or negotiating better rates with existing marketing vendors.\\n- Utilities: Implement energy-saving measures to reduce utility consumption. Conduct an energy audit to identify areas for improvement. Negotiate better rates with utility providers.\\n- Office_Supplies: Implement a policy to reduce waste and encourage responsible use of office supplies. Negotiate bulk discounts with suppliers.\\n- Maintenance: Implement a preventative maintenance program to reduce the likelihood of costly repairs. Negotiate service contracts with maintenance providers.\\n\\n\\nInvestment Opportunities: Based on the current financial data, potential investment opportunities could include: 1) Investing in technology or equipment that improves operational efficiency and reduces raw material waste. 2) Expanding into new markets or product lines to diversify revenue streams and reduce reliance on existing products. 3) Investing in employee training and development to improve productivity and reduce employee turnover. 4) Exploring strategic partnerships or acquisitions to gain access to new technologies, markets, or resources. A thorough market analysis and financial modeling should be conducted before making any investment decisions.\\n\\nRisk Assessment: The company faces several financial risks. High reliance on a single revenue stream makes it vulnerable to market fluctuations. The significant expense related to raw materials exposes the company to price volatility. The loan payment represents a fixed financial obligation that could strain cash flow during periods of low revenue. The relatively low profit margin indicates limited financial flexibility. To mitigate these risks, the company should diversify its revenue streams, hedge against raw material price fluctuations, maintain a healthy cash reserve, and continuously monitor its financial performance.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the System and Instruction prompts are successfully masked!"
      ],
      "metadata": {
        "id": "3enWUM0jV-jV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "82a9a7c1-bb8c-488e-a6b3-3f38b8c94352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "5.748 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "bae5aed0-c9b6-4a82-aa4d-2fbebeb438e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 780 | Num Epochs = 1 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 83,886,080/8,000,000,000 (1.05% trained)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzelsayed722\u001b[0m (\u001b[33mzelsayed722-mansoura-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250413_201635-u7suxu7s</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/zelsayed722-mansoura-university/huggingface/runs/u7suxu7s' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/zelsayed722-mansoura-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/zelsayed722-mansoura-university/huggingface' target=\"_blank\">https://wandb.ai/zelsayed722-mansoura-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/zelsayed722-mansoura-university/huggingface/runs/u7suxu7s' target=\"_blank\">https://wandb.ai/zelsayed722-mansoura-university/huggingface/runs/u7suxu7s</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 17:33, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.304900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.318600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.315300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.291500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.209800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.114300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.935000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.914200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.802800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.717100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.754300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.619600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.605100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.592400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.530300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.559900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.566400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.500200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.489800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.472900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.463000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.492400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.460200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.420700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.506200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.421400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.395200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.424500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.451600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.399600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.454000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.390500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.429600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.428100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.448100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.468000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.424100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.373500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.392700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.446100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.364200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.363200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.395900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.347900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.377900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.355600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.398400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.434400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.366300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.338500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.398400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.367100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.419500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.360700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.348300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.399600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.376800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.365800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.366500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n",
        "\n",
        "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "a8bab64c-a7e2-4edb-f5a7-15b893a55842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\\n{'Date': '2018-05-01',\\n 'Month': 5,\\n 'Year': 2018,\\n 'Total_Revenue': 526352.11,\\n 'Employee_Salaries': 165851.51,\\n 'Loan_Payment': 23506.69,\\n 'Raw_Materials': 94326.72,\\n 'Utilities': 9173.98,\\n 'Rent': 17038.7,\\n 'Marketing': 29864.6,\\n 'Insurance': 15844.99,\\n 'Office_Supplies': 4422.06,\\n 'Maintenance': 8500.11,\\n 'Taxes': 51556.86,\\n 'Transfer_Money': 35452.41,\\n 'Profits': 106265.88999999996}\\n    <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nProfitability Analysis: The profitability of the company can be assessed by comparing the 'Total_Revenue' with the 'Profits'. In this case, the profit margin is approximately 20.21% (Profits / Total_Revenue). This indicates a reasonable level of profitability. However, further analysis of revenue growth trends and cost components (such as Employee_Salaries and Marketing) over time is crucial to understand the sustainability of this profit margin. Monitoring the 'Profitability_Ratio' (Profitability Index) over different time periods can provide insights into revenue growth effectiveness and cost efficiency.\\n\\nCash Flow Recommendations: To improve cash flow management, several strategies can be implemented. First, negotiate extended payment terms with suppliers to delay cash outflows. Second, optimize the 'Transfer_Money' process by streamlining the transfer mechanisms to reduce transfer times and associated costs. Third, review the 'Employee_Salaries' and 'Marketing' expenses to identify potential efficiencies. Fourth, consider short-term investments for surplus cash to earn interest. Lastly, implement a cash flow forecasting system to anticipate future cash needs and potential shortfalls.\\n\\nExpense Optimization Strategies:\\n- Employee_Salaries: Analyze salary structures and staffing levels to identify potential savings without compromising productivity. Consider performance-based compensation to align employee incentives with company profitability.\\n- Marketing: Evaluate the effectiveness of marketing campaigns and allocate resources to channels with the highest ROI. Explore cost-effective marketing strategies such as social media marketing and content marketing.\\n- Raw_Materials: Negotiate better pricing with raw material suppliers or explore alternative, cost-effective materials without compromising quality.\\n- Utilities: Implement energy-saving measures to reduce utility consumption and costs.\\n- Maintenance: Develop a preventative maintenance program to reduce the likelihood of costly repairs and downtime.\\n\\n\\nInvestment Opportunities: Based on the current profitability, the company could consider reinvesting profits into growth opportunities. Potential areas for investment include: expanding into new markets, developing new products or services, investing in technology to improve operational efficiency, or increasing marketing efforts to boost sales. A detailed market analysis and business plan should be developed before making any significant investment decisions.\\n\\nRisk Assessment: Key financial risks include fluctuations in raw material prices, unexpected increases in employee salaries or benefits, and changes in market conditions that impact sales volume. Mitigation strategies include: hedging against commodity price risks, implementing performance-based compensation to align employee incentives with company profitability, and diversifying sales channels to reduce reliance on any single market or product. Regular monitoring of key financial metrics and market trends is crucial to identify and address potential risks in a timely manner.<|eot_id|>\"]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "{'Date': '2018-05-01',\n",
        " 'Month': 5,\n",
        " 'Year': 2018,\n",
        " 'Total_Revenue': 526352.11,\n",
        " 'Employee_Salaries': 165851.51,\n",
        " 'Loan_Payment': 23506.69,\n",
        " 'Raw_Materials': 94326.72,\n",
        " 'Utilities': 9173.98,\n",
        " 'Rent': 17038.7,\n",
        " 'Marketing': 29864.6,\n",
        " 'Insurance': 15844.99,\n",
        " 'Office_Supplies': 4422.06,\n",
        " 'Maintenance': 8500.11,\n",
        " 'Taxes': 51556.86,\n",
        " 'Transfer_Money': 35452.41,\n",
        " 'Profits': 106265.88999999996}\n",
        "    \"\"\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 1024, use_cache = True,\n",
        "                         temperature = 1.5, min_p = 0.1)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2pEuRb1r2Vg",
        "outputId": "2edcd9c9-6214-42aa-ae32-b90a1c485571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profitability Analysis: The profit margin for this period is approximately 20.1% (Profits/Total_Revenue). Revenue growth appears stagnant, with a slight decrease from 526352.11 to 523000.00 if we assume the profit margin remains constant, revenue would increase to 656000.00. Expense management is crucial; Employee_Salaries and Raw_Materials represent the largest expenses. A detailed review of these costs is necessary. Marketing spends seem reasonable, but their return on investment (ROI) should be analyzed. Interest expenses from Loans should be compared against alternative borrowing options. The impact of Transfer_Money needs to be assessed, is this a necessary expense or can it be optimized?\n",
            "\n",
            "Cash Flow Recommendations: To improve cash flow, consider the following strategies: 1) Negotiate extended payment terms with suppliers for Raw_Materials and Utilities. 2) Implement a robust accounts receivable process to ensure timely collection of payments from customers. 3) Explore options for refinancing Loans at better interest rates. 4) Analyze the Transfer_Money expense to identify opportunities for reduction. 5) Build a cash reserve to buffer against unforeseen expenses and revenue fluctuations.\n",
            "\n",
            "Expense Optimization Strategies:\n",
            "- Employee_Salaries: Evaluate salary structures and employee productivity. Consider performance-based incentives to optimize workforce efficiency.\n",
            "- Raw_Materials: Negotiate better pricing with suppliers or explore alternative, cost-effective materials without compromising quality.\n",
            "- Marketing: Analyze the ROI of current marketing campaigns and reallocate resources to more effective channels. Consider cost-saving measures such as more efficient ad targeting or leveraging user-generated content.\n",
            "- Transfer_Money: Investigate the necessity and efficiency of these transfers. If possible, reduce or eliminate unnecessary transfers.\n",
            "- Office_Supplies: Implement a stricter procurement process and encourage employees to use supplies efficiently.\n",
            "\n",
            "\n",
            "Investment Opportunities: Given the current profitability, consider reinvesting profits into areas that can generate higher returns. Potential investment opportunities include: 1) Expanding into new markets or product lines if market research indicates a high demand. 2) Investing in technologies that can automate processes, reduce labor costs, and improve operational efficiency. 3) Enhancing employee training and development to improve productivity and employee retention. A detailed market analysis and ROI calculation should precede any investment decision.\n",
            "\n",
            "\n",
            "Risk Assessment: Key financial risks include: 1) Fluctuations in Raw_Materials prices, which can impact profitability. 2) Economic downturns, which can reduce revenue. 3) Increasing competition, which can erode market share. 4) Interest rate risk from variable-rate Loans. Mitigation strategies include: 1) Hedging against Raw_Materials price fluctuations through derivatives or long-term contracts. 2) Diversifying revenue streams to reduce reliance on any single market or product. 3) Maintaining a healthy cash reserve to weather economic shocks. 4) Regularly monitoring interest rates and adjusting borrowing strategies accordingly.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "{'Date': '2018-05-01',\n",
        " 'Month': 5,\n",
        " 'Year': 2018,\n",
        " 'Total_Revenue': 526352.11,\n",
        " 'Employee_Salaries': 165851.51,\n",
        " 'Loan_Payment': 23506.69,\n",
        " 'Raw_Materials': 94326.72,\n",
        " 'Utilities': 9173.98,\n",
        " 'Rent': 17038.7,\n",
        " 'Marketing': 29864.6,\n",
        " 'Insurance': 15844.99,\n",
        " 'Office_Supplies': 4422.06,\n",
        " 'Maintenance': 8500.11,\n",
        " 'Taxes': 51556.86,\n",
        " 'Transfer_Money': 35452.41,\n",
        " 'Profits': 106265.88999999996}\n",
        "    \"\"\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 3000,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "ed695897-b1d4-4dbb-d601-cd1b01070e96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('business_financial_model/tokenizer_config.json',\n",
              " 'business_financial_model/special_tokens_map.json',\n",
              " 'business_financial_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "model.save_pretrained(\"business_financial_model\") # Local saving\n",
        "tokenizer.save_pretrained(\"business_financial_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"vllm>=0.4.0\" huggingface_hub"
      ],
      "metadata": {
        "id": "133vugxU4bKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!vllm serve \\\n",
        "  --model unsloth/Meta-Llama-3.1-8B-Instruct \\\n",
        "  --quantization awq \\  # 4-bit quantization (faster + cheaper)\n",
        "  --enable-lora \\\n",
        "  --lora-modules my-lora=./path-to-your-lora-adapter \\  # Local path or HF Hub ID\n",
        "  --max-lora-rank 64 \\\n",
        "  --host 0.0.0.0 --port 8000"
      ],
      "metadata": {
        "id": "-SgtT8DOCHB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct\"\n",
        "ter_model_id = \"personal_financial_model\"\n",
        "business_model_id = \"business_financial_model\"\n",
        "\n",
        "!nohup vllm serve $model_name \\\n",
        "  --dtype half \\\n",
        "  --gpu-memory-utilization 0.8 \\\n",
        "  --max-lora-rank 64 \\\n",
        "  --enable-lora \\\n",
        "  --lora-modules personal-lora=$ter_model_id business-lora=$business_model_id \\\n",
        "  > vllm.log 2>&1 &"
      ],
      "metadata": {
        "id": "32-qfMRdsmqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 30 nohup.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZR0y9eT6RK0",
        "outputId": "4faf74dd-5965-427c-94cd-cb2f62a9dfc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-13 20:48:23.495743: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744577303.524686   23713 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744577303.533823   23713 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO 04-13 20:48:29 __init__.py:190] Automatically detected platform cuda.\n",
            "usage: vllm [-h] [-v] {serve,complete,chat} ...\n",
            "vllm: error: unrecognized arguments: --lora-base unsloth/Meta-Llama-3.1-8B-Instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"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\")\n",
        "model.push_to_hub(\"sayed-zaki-122/business_financial_model\") # Online saving\n",
        "tokenizer.push_to_hub(\"sayed-zaki-122/business_financial_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "495e77e09b9347fcabfe13f2b7d54dc5",
            "da299a55c9db45c592edd4698b9c7be0",
            "2868038ee80d4e208ce6a4926f086a42",
            "ce9af1a162744a40ab9cae39242466fd",
            "94c4eec0137c4329b3d3bdf648ff87a3",
            "cc8434a341ed4bf1a1fafd27f7fac669",
            "14d0733ab57347f08c7d06d7c0a784a5",
            "e3bbdf1272184081892b6c99e1c2b015",
            "2fe834b4827b4a4a88a5f378868affec",
            "1844f79128c4489cae6b6c958999f298",
            "9c2bb0dcb8b641d9a59966548f944cd4",
            "feec153139cc44afadba5c8a129f3273",
            "8895d764ea89445f882d608cbd6a9790",
            "12cbd62ead9b403db3ae1f3d8894f193",
            "def072f2d6664a799df6d9baba40aa00",
            "56ea986f6b3f4c17810c3c6fa84edabb",
            "35fe530b4246433297d2209d09d83187",
            "bd94d1ff032f4aec9da9daa9ef5002dd",
            "dd8e0020182941068380862949715fb4",
            "dadcd3cce8654b83871ca11d8a19220b",
            "b2189b8cba2f434f971003d582dba6ff",
            "5ff88490bc86486490cd05e76bc21901",
            "624efb49ba08412db103ac45b869f8b2",
            "d07ca3ba66eb43458529fd71af49f0b0",
            "ac68fbabf2e947079bdb3d295f8adcc5",
            "284409e6b77a40288113ac429d473871",
            "297410d3d2a04220ab58720ce90e3167",
            "5249ca67ac3644ab850e8de36a3f57ac",
            "b0d024eb0fde4e5fb929905f64532b59",
            "57d9c218a18841759d1e510e17b5a0c5",
            "d9d553955334493ea4195eb3c8c9b0aa",
            "9d8bc70d0c6743cf8f201056a715892a",
            "fd38cafe0c584ed082bc6874995fbd24",
            "b05ce756ca0d4ecb8582fd1314e6b56f",
            "197d95e8796f40eda244810e9d2a0cb3",
            "3ad32c4b41e74d74ad2072c05f88474e",
            "edde8e3d9acf45ca81e87c042a1187ae",
            "93e55e3affb84fe9a91e0eac55c3335c",
            "fe77c33e52b445a8a50ae6cb9f817e15",
            "a1c1c6fe5eaf4a3e8f3820d543fa5cd4",
            "6820fcd29a9b45e8877577a159ce72d7",
            "8b4753e86bad4cfca8a31ac6702e4afc",
            "76f3a88eb8434b22974333fdddcea1af",
            "9104b7b110fd496d9ad83260d2cce712",
            "2850ba6a3d2842e99bd72b1c98a06db3",
            "93c15c6d83be432095649c46800701d7",
            "1fd8f8e7b1b148a193e8927065c55292",
            "bab9b4617ebb4e85ba9ea819d78aafc9",
            "d4c8f9f078bd4f66826d6aaf6d0851e1",
            "0bcb54d1d37a4b6da1a030237a687b40",
            "d603ded7253f40ebbd35c836c0b6793a",
            "fbfe03afe9eb440198833b709e25299e",
            "8cdcf961f17b4728bd19ad790754278f",
            "7c1729d791924119a1cf76a33b6c3a79",
            "8c010685a9ba4493a8806e1967168760"
          ]
        },
        "id": "waZhK830E3Pj",
        "outputId": "cb4fda95-ad46-425b-b5b7-61726661277d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "495e77e09b9347fcabfe13f2b7d54dc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/336M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feec153139cc44afadba5c8a129f3273"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "624efb49ba08412db103ac45b869f8b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b05ce756ca0d4ecb8582fd1314e6b56f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2850ba6a3d2842e99bd72b1c98a06db3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/sayed-zaki-122/business_financial_model/commit/2c80dde6e19d74abc39b0a4b67e136742eb3ac82', commit_message='Upload tokenizer', commit_description='', oid='2c80dde6e19d74abc39b0a4b67e136742eb3ac82', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sayed-zaki-122/business_financial_model', endpoint='https://huggingface.co', repo_type='model', repo_id='sayed-zaki-122/business_financial_model'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "f145bcb9-abc9-43e0-ce16-91a0a7caa585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Recommended savings: Based on your income and expenses, I recommend aiming to save at least 20% of your income, which is approximately 657.58. This includes your existing savings allocations (Investment, Emergency Fund, and Retirement) and potential areas for increase (Consider increasing savings to reach this goal).\n",
            "Optimized budget: {'Income': 3461.88,\n",
            " 'Electricity': 68.92,\n",
            " 'Gas': 48.39,\n",
            " 'Internet': 59.03,\n",
            " 'Water': 34.7,\n",
            " 'Food': 361.19,\n",
            " 'Groceries': 291.87,\n",
            " 'Rent': 843.46,\n",
            " 'Transportation': 153.93,\n",
            " 'Healthcare': 99.87,\n",
            " 'Shopping': 200.0,\n",
            " 'Entertainment': 75.0,\n",
            " 'Dining Out': 125.0,\n",
            " 'Subscription Services': 30.0,\n",
            " 'Clothing': 70.0,\n",
            " 'Electronics': 30.0,\n",
            " 'Zakat': 215.79,\n",
            " 'Investment': 400.0,\n",
            " 'Emergency Fund': 300.0,\n",
            " 'Retirement': 450.0,\n",
            " 'Education': 150.0,\n",
            " 'Travel': 200.0,\n",
            " 'Gifts': 45.0,\n",
            " 'Home Maintenance': 90.0,\n",
            " 'Others': 80.0}\n",
            "Financial tips: 1. Track your spending closely to identify areas where you can cut back. 2. Set realistic financial goals, such as increasing your savings or paying off debt, and create a plan to achieve them. 3. Consider automating your savings and investments to ensure consistent contributions. 4. Review your subscription services and cancel any that you don't use regularly. 5. Look for ways to reduce your food expenses, such as meal planning and reducing food waste.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "if True:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"personal_financial_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "    {'Income': 3271.32,\n",
        " 'Electricity': 68.8,\n",
        " 'Gas': 44.46,\n",
        " 'Internet': 63.46,\n",
        " 'Water': 43.37,\n",
        " 'Food': 387.04,\n",
        " 'Groceries': 304.22,\n",
        " 'Rent': 861.92,\n",
        " 'Transportation': 159.58,\n",
        " 'Healthcare': 99.91,\n",
        " 'Shopping': 173.13,\n",
        " 'Entertainment': 102.72,\n",
        " 'Dining Out': 153.67,\n",
        " 'Subscription Services': 31.06,\n",
        " 'Clothing': 95.52,\n",
        " 'Electronics': 52.21,\n",
        " 'Zakat': 222.91,\n",
        " 'Investment': 359.92,\n",
        " 'Emergency Fund': 229.5,\n",
        " 'Retirement': 415.64,\n",
        " 'Education': 149.66,\n",
        " 'Travel': 305.61,\n",
        " 'Gifts': 52.39,\n",
        " 'Home Maintenance': 118.51,\n",
        " 'Others': 89.79}\n",
        "    \"\"\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 1024,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f480457-f6b9-41e2-b6a2-7e503eaddc2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        }
      ],
      "source": [
        "if True:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"personal_financial_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"personal_financial_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "d20ef766-e68f-43ea-9ce1-eaa99cfab0a2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'LlamaForCausalLM' object has no attribute 'push_to_hub_merged'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_modules\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_modules\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PeftModelForCausalLM' object has no attribute 'push_to_hub_merged'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_modules\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_modules\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'push_to_hub_merged'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-8ef94e903d52>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Merge to 16bit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# if True: model.save_pretrained(\"model\", safe_serialization=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_to_hub_merged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hf/model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"merged_16bit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"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\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Merge to 4bit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"base_model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_peft_config_as_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_modules\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_modules\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LlamaForCausalLM' object has no attribute 'push_to_hub_merged'"
          ]
        }
      ],
      "source": [
        "# Merge to 16bit\n",
        "# if True: model.save_pretrained(\"model\", safe_serialization=True)\n",
        "if True: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"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\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gx_OaJaU-_hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDp0zNpwe6U_"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html).\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!vllm serve unsloth/Meta-Llama-3.1-8B-Instruct --enable-lora --lora-modules business-lora=sayed-zaki-122/business_financial_model personal-lora=sayed-zaki-122/personal_financial_model --max-lora-rank 64 --host 0.0.0.0 --port 8000 --gpu-memory-utilization 0.6  # Lower due to higher memory usage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4YnARpUDJQp",
        "outputId": "53ae1be2-b6e2-4330-a445-9613af9eb005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-13 21:44:39.866572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744580679.888162   38449 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744580679.894421   38449 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO 04-13 21:44:42 __init__.py:190] Automatically detected platform cuda.\n",
            "INFO 04-13 21:44:43 api_server.py:840] vLLM API server version 0.7.2\n",
            "INFO 04-13 21:44:43 api_server.py:841] args: Namespace(subparser='serve', model_tag='unsloth/Meta-Llama-3.1-8B-Instruct', config='', host='0.0.0.0', port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=[LoRAModulePath(name='business-lora', path='sayed-zaki-122/business_financial_model', base_model_name=None), LoRAModulePath(name='personal-lora', path='sayed-zaki-122/personal_financial_model', base_model_name=None)], prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, enable_reasoning=False, reasoning_parser=None, tool_call_parser=None, tool_parser_plugin='', model='unsloth/Meta-Llama-3.1-8B-Instruct', task='auto', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=None, guided_decoding_backend='xgrammar', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=None, enable_prefix_caching=None, disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.6, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=True, enable_lora_bias=False, max_loras=1, max_lora_rank=64, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', generation_config=None, override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, dispatch_function=<function serve at 0x12a235f89a80>)\n",
            "INFO 04-13 21:44:44 api_server.py:206] Started engine process with PID 38516\n",
            "2025-04-13 21:44:52.899799: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744580692.933277   38516 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744580692.944958   38516 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO 04-13 21:44:56 __init__.py:190] Automatically detected platform cuda.\n",
            "INFO 04-13 21:45:04 config.py:542] This model supports multiple tasks: {'embed', 'score', 'reward', 'generate', 'classify'}. Defaulting to 'generate'.\n",
            "WARNING 04-13 21:45:04 arg_utils.py:1145] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.\n",
            "INFO 04-13 21:45:14 config.py:542] This model supports multiple tasks: {'generate', 'reward', 'score', 'embed', 'classify'}. Defaulting to 'generate'.\n",
            "WARNING 04-13 21:45:14 arg_utils.py:1145] The model has a long context length (131072). This may cause OOM errors during the initial memory profiling phase, or result in low performance due to small KV cache space. Consider setting --max-model-len to a smaller value.\n",
            "INFO 04-13 21:45:14 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='unsloth/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='unsloth/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/Meta-Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=True, \n",
            "INFO 04-13 21:45:16 cuda.py:179] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 04-13 21:45:16 cuda.py:227] Using XFormers backend.\n",
            "ERROR 04-13 21:45:16 engine.py:389] Bfloat16 is only supported on GPUs with compute capability of at least 8.0. Your Tesla T4 GPU has compute capability 7.5. You can use float16 instead by explicitly setting the`dtype` flag in CLI, for example: --dtype=half.\n",
            "ERROR 04-13 21:45:16 engine.py:389] Traceback (most recent call last):\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 380, in run_mp_engine\n",
            "ERROR 04-13 21:45:16 engine.py:389]     engine = MQLLMEngine.from_engine_args(engine_args=engine_args,\n",
            "ERROR 04-13 21:45:16 engine.py:389]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 123, in from_engine_args\n",
            "ERROR 04-13 21:45:16 engine.py:389]     return cls(ipc_path=ipc_path,\n",
            "ERROR 04-13 21:45:16 engine.py:389]            ^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 75, in __init__\n",
            "ERROR 04-13 21:45:16 engine.py:389]     self.engine = LLMEngine(*args, **kwargs)\n",
            "ERROR 04-13 21:45:16 engine.py:389]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\", line 273, in __init__\n",
            "ERROR 04-13 21:45:16 engine.py:389]     self.model_executor = executor_class(vllm_config=vllm_config, )\n",
            "ERROR 04-13 21:45:16 engine.py:389]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/executor_base.py\", line 51, in __init__\n",
            "ERROR 04-13 21:45:16 engine.py:389]     self._init_executor()\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/uniproc_executor.py\", line 41, in _init_executor\n",
            "ERROR 04-13 21:45:16 engine.py:389]     self.collective_rpc(\"init_device\")\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/uniproc_executor.py\", line 51, in collective_rpc\n",
            "ERROR 04-13 21:45:16 engine.py:389]     answer = run_method(self.driver_worker, method, args, kwargs)\n",
            "ERROR 04-13 21:45:16 engine.py:389]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/utils.py\", line 2220, in run_method\n",
            "ERROR 04-13 21:45:16 engine.py:389]     return func(*args, **kwargs)\n",
            "ERROR 04-13 21:45:16 engine.py:389]            ^^^^^^^^^^^^^^^^^^^^^\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/worker/worker.py\", line 157, in init_device\n",
            "ERROR 04-13 21:45:16 engine.py:389]     _check_if_gpu_supports_dtype(self.model_config.dtype)\n",
            "ERROR 04-13 21:45:16 engine.py:389]   File \"/usr/local/lib/python3.11/dist-packages/vllm/worker/worker.py\", line 525, in _check_if_gpu_supports_dtype\n",
            "ERROR 04-13 21:45:16 engine.py:389]     raise ValueError(\n",
            "ERROR 04-13 21:45:16 engine.py:389] ValueError: Bfloat16 is only supported on GPUs with compute capability of at least 8.0. Your Tesla T4 GPU has compute capability 7.5. You can use float16 instead by explicitly setting the`dtype` flag in CLI, for example: --dtype=half.\n",
            "Process SpawnProcess-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 391, in run_mp_engine\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 380, in run_mp_engine\n",
            "    engine = MQLLMEngine.from_engine_args(engine_args=engine_args,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 123, in from_engine_args\n",
            "    return cls(ipc_path=ipc_path,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/multiprocessing/engine.py\", line 75, in __init__\n",
            "    self.engine = LLMEngine(*args, **kwargs)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/engine/llm_engine.py\", line 273, in __init__\n",
            "    self.model_executor = executor_class(vllm_config=vllm_config, )\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/executor_base.py\", line 51, in __init__\n",
            "    self._init_executor()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/uniproc_executor.py\", line 41, in _init_executor\n",
            "    self.collective_rpc(\"init_device\")\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/executor/uniproc_executor.py\", line 51, in collective_rpc\n",
            "    answer = run_method(self.driver_worker, method, args, kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/utils.py\", line 2220, in run_method\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/worker/worker.py\", line 157, in init_device\n",
            "    _check_if_gpu_supports_dtype(self.model_config.dtype)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/worker/worker.py\", line 525, in _check_if_gpu_supports_dtype\n",
            "    raise ValueError(\n",
            "ValueError: Bfloat16 is only supported on GPUs with compute capability of at least 8.0. Your Tesla T4 GPU has compute capability 7.5. You can use float16 instead by explicitly setting the`dtype` flag in CLI, for example: --dtype=half.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/vllm\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/scripts.py\", line 204, in main\n",
            "    args.dispatch_function(args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/scripts.py\", line 44, in serve\n",
            "    uvloop.run(run_server(args))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvloop/__init__.py\", line 105, in run\n",
            "    return runner.run(wrapper())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvloop/__init__.py\", line 61, in wrapper\n",
            "    return await main\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 875, in run_server\n",
            "    async with build_async_engine_client(args) as engine_client:\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 136, in build_async_engine_client\n",
            "    async with build_async_engine_client_from_engine_args(\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 230, in build_async_engine_client_from_engine_args\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Engine process failed to start. See stack trace for the root cause.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show vllm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_K88t2cDzJJ",
        "outputId": "472099a4-85d9-4af0-b384-3440320b7c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: vllm\n",
            "Version: 0.7.2\n",
            "Summary: A high-throughput and memory-efficient inference and serving engine for LLMs\n",
            "Home-page: https://github.com/vllm-project/vllm\n",
            "Author: vLLM Team\n",
            "Author-email: \n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: aiohttp, blake3, cloudpickle, compressed-tensors, depyf, einops, fastapi, filelock, gguf, importlib_metadata, lark, lm-format-enforcer, mistral_common, msgspec, numpy, nvidia-ml-py, openai, outlines, partial-json-parser, pillow, prometheus-fastapi-instrumentator, prometheus_client, protobuf, psutil, py-cpuinfo, pydantic, pyyaml, pyzmq, ray, requests, sentencepiece, tiktoken, tokenizers, torch, torchaudio, torchvision, tqdm, transformers, typing_extensions, uvicorn, xformers, xgrammar\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3IlnnFYE8F-",
        "outputId": "ba782ab3-ff86-4ee7-ce60-ab2a1b33b4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr 13 21:35:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0             27W /   70W |   13796MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "# base_model = AutoModelForCausalLM.from_pretrained(\"unsloth/Meta-Llama-3.1-8B-Instruct\", device_map=\"auto\")\n",
        "model = PeftModel.from_pretrained(base_model, \"personal_financial_model\")\n",
        "\n",
        "model.save_pretrained(\"final_personal_financial\")  # This will save it in the format vLLM expects\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "vbdyaRlQKLw4",
        "outputId": "74bfb2aa-a97f-4698-9fe7-93d846be0637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'base_model.model.model.model.embed_tokens'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-32b7bda54fc3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# base_model = AutoModelForCausalLM.from_pretrained(\"unsloth/Meta-Llama-3.1-8B-Instruct\", device_map=\"auto\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"personal_financial_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"final_personal_financial\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will save it in the format vLLM expects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m             )\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         load_result = model.load_adapter(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mload_adapter\u001b[0;34m(self, model_id, adapter_name, is_trainable, torch_device, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, **kwargs)\u001b[0m\n\u001b[1;32m   1288\u001b[0m                 )\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_offload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapters_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0mdispatch_model_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"offload_index\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffload_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m_update_offload\u001b[0;34m(self, offload_index, adapters_weights)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                         \u001b[0msuffix_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                         \u001b[0mextended_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mblock_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msafe_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msuffix_pos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                         \u001b[0msafe_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextended_prefix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseTunerLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                             \u001b[0mfinal_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextended_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".base_layer\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msafe_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msuffix_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'base_model.model.model.model.embed_tokens'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_id = \"unsloth/Meta-Llama-3.1-8B-Instruct\"\n",
        "adapter1_path = \"business_financial_model\"\n",
        "adapter2_path = \"personal_financial_model\"\n",
        "\n",
        "!nohup vllm serve \"$base_model_id\" --dtype=half --gpu-memory-utilization 0.8 --max_lora_rank 64 --enable-lora --lora-modules adapter1=$adapter1_path adapter2=$adapter2_path &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HHQgPYtFBY9",
        "outputId": "d615d65b-d8e1-46d5-c14e-addc135d0c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 30 nohup.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRrmULYQHgBF",
        "outputId": "b3819e50-a9dd-4170-cc1a-d8ef48a5ad58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/scripts.py\", line 44, in serve\n",
            "    uvloop.run(run_server(args))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvloop/__init__.py\", line 105, in run\n",
            "    return runner.run(wrapper())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvloop/__init__.py\", line 61, in wrapper\n",
            "    return await main\n",
            "           ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 875, in run_server\n",
            "    async with build_async_engine_client(args) as engine_client:\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 136, in build_async_engine_client\n",
            "    async with build_async_engine_client_from_engine_args(\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
            "    return await anext(self.gen)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/vllm/entrypoints/openai/api_server.py\", line 230, in build_async_engine_client_from_engine_args\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Engine process failed to start. See stack trace for the root cause.\n",
            "2025-04-13 21:56:17.809527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744581377.830870   41547 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744581377.837428   41547 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "INFO 04-13 21:56:20 __init__.py:190] Automatically detected platform cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_merged(\"merged_model\")\n",
        "model.save_pretrained_lora(\"lora_adapter_folder\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "t4_INRQDIpl3",
        "outputId": "90c1a05c-fff4-4c8d-fe30-16c2fa761743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'LlamaForCausalLM' object has no attribute 'save_pretrained_merged'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_modules\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_modules\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PeftModelForCausalLM' object has no attribute 'save_pretrained_merged'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_modules\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_modules\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'save_pretrained_merged'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-877d476d0378>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained_merged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"merged_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained_lora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lora_adapter_folder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"base_model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_peft_config_as_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_modules\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_modules\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LlamaForCausalLM' object has no attribute 'save_pretrained_merged'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zNl7lwMKNr4R"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dcac68802f1d476f982a30928ca197c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffdb8ccef9304d99ac9f1d82f7e05f5b",
              "IPY_MODEL_aeda3965b55e4d698a36a20ed29fbf66",
              "IPY_MODEL_7d21fc25b2134c22892ad43fbefc59c5"
            ],
            "layout": "IPY_MODEL_feeea8eb37ee402b8bff60a8412367e8"
          }
        },
        "ffdb8ccef9304d99ac9f1d82f7e05f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e35aae97faf461a9186e8963a195236",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_899d233c052c49dea9b5a55d727762b6",
            "value": "Unsloth:â€‡Tokenizingâ€‡[&quot;text&quot;]â€‡(num_proc=2):â€‡100%"
          }
        },
        "aeda3965b55e4d698a36a20ed29fbf66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2960fd59a3e140c382425b5a8fd46942",
            "max": 780,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44faf1fa2b8e4c689ebef910e85fc72f",
            "value": 780
          }
        },
        "7d21fc25b2134c22892ad43fbefc59c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8789041c4834dc68f3f442f10ef4d7d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dab3bf6981704269886989739e31727b",
            "value": "â€‡780/780â€‡[00:03&lt;00:00,â€‡253.64â€‡examples/s]"
          }
        },
        "feeea8eb37ee402b8bff60a8412367e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e35aae97faf461a9186e8963a195236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "899d233c052c49dea9b5a55d727762b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2960fd59a3e140c382425b5a8fd46942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44faf1fa2b8e4c689ebef910e85fc72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8789041c4834dc68f3f442f10ef4d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab3bf6981704269886989739e31727b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3abe868cc2e146f68f0388bebeeb3909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63e8a456d10549279c1f0dc964c1e63b",
              "IPY_MODEL_11f2f5c0e43b4d81ac150b24c5760d34",
              "IPY_MODEL_6bfa8112bee94c39bba066fdac853277"
            ],
            "layout": "IPY_MODEL_e4e5c2a23b834d5e8845d6ad249139d4"
          }
        },
        "63e8a456d10549279c1f0dc964c1e63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28be94b4dc74397abba929360a9d744",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dbde1d2ee54f45db85206a22ed4c8f60",
            "value": "Mapâ€‡(num_proc=2):â€‡100%"
          }
        },
        "11f2f5c0e43b4d81ac150b24c5760d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29dee39fd0d44d19b88a1270e272662c",
            "max": 780,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49894d0e5f1b4a01b9501c7c63763fcf",
            "value": 780
          }
        },
        "6bfa8112bee94c39bba066fdac853277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b60b4d61133f4ddaa8a3f8862badb0f1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2eb1122f1e0f4b59baa1b2fca658b4bd",
            "value": "â€‡780/780â€‡[00:00&lt;00:00,â€‡1046.16â€‡examples/s]"
          }
        },
        "e4e5c2a23b834d5e8845d6ad249139d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28be94b4dc74397abba929360a9d744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbde1d2ee54f45db85206a22ed4c8f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29dee39fd0d44d19b88a1270e272662c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49894d0e5f1b4a01b9501c7c63763fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b60b4d61133f4ddaa8a3f8862badb0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb1122f1e0f4b59baa1b2fca658b4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "495e77e09b9347fcabfe13f2b7d54dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da299a55c9db45c592edd4698b9c7be0",
              "IPY_MODEL_2868038ee80d4e208ce6a4926f086a42",
              "IPY_MODEL_ce9af1a162744a40ab9cae39242466fd"
            ],
            "layout": "IPY_MODEL_94c4eec0137c4329b3d3bdf648ff87a3"
          }
        },
        "da299a55c9db45c592edd4698b9c7be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc8434a341ed4bf1a1fafd27f7fac669",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_14d0733ab57347f08c7d06d7c0a784a5",
            "value": "100%"
          }
        },
        "2868038ee80d4e208ce6a4926f086a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3bbdf1272184081892b6c99e1c2b015",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2fe834b4827b4a4a88a5f378868affec",
            "value": 1
          }
        },
        "ce9af1a162744a40ab9cae39242466fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1844f79128c4489cae6b6c958999f298",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9c2bb0dcb8b641d9a59966548f944cd4",
            "value": "â€‡1/1â€‡[00:03&lt;00:00,â€‡â€‡3.66s/it]"
          }
        },
        "94c4eec0137c4329b3d3bdf648ff87a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc8434a341ed4bf1a1fafd27f7fac669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d0733ab57347f08c7d06d7c0a784a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3bbdf1272184081892b6c99e1c2b015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe834b4827b4a4a88a5f378868affec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1844f79128c4489cae6b6c958999f298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c2bb0dcb8b641d9a59966548f944cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feec153139cc44afadba5c8a129f3273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8895d764ea89445f882d608cbd6a9790",
              "IPY_MODEL_12cbd62ead9b403db3ae1f3d8894f193",
              "IPY_MODEL_def072f2d6664a799df6d9baba40aa00"
            ],
            "layout": "IPY_MODEL_56ea986f6b3f4c17810c3c6fa84edabb"
          }
        },
        "8895d764ea89445f882d608cbd6a9790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35fe530b4246433297d2209d09d83187",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bd94d1ff032f4aec9da9daa9ef5002dd",
            "value": "adapter_model.safetensors:â€‡"
          }
        },
        "12cbd62ead9b403db3ae1f3d8894f193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd8e0020182941068380862949715fb4",
            "max": 335604696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dadcd3cce8654b83871ca11d8a19220b",
            "value": 335604696
          }
        },
        "def072f2d6664a799df6d9baba40aa00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2189b8cba2f434f971003d582dba6ff",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5ff88490bc86486490cd05e76bc21901",
            "value": "â€‡336M/?â€‡[00:03&lt;00:00,â€‡177MB/s]"
          }
        },
        "56ea986f6b3f4c17810c3c6fa84edabb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35fe530b4246433297d2209d09d83187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd94d1ff032f4aec9da9daa9ef5002dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd8e0020182941068380862949715fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dadcd3cce8654b83871ca11d8a19220b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2189b8cba2f434f971003d582dba6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff88490bc86486490cd05e76bc21901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "624efb49ba08412db103ac45b869f8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d07ca3ba66eb43458529fd71af49f0b0",
              "IPY_MODEL_ac68fbabf2e947079bdb3d295f8adcc5",
              "IPY_MODEL_284409e6b77a40288113ac429d473871"
            ],
            "layout": "IPY_MODEL_297410d3d2a04220ab58720ce90e3167"
          }
        },
        "d07ca3ba66eb43458529fd71af49f0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5249ca67ac3644ab850e8de36a3f57ac",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b0d024eb0fde4e5fb929905f64532b59",
            "value": "README.md:â€‡100%"
          }
        },
        "ac68fbabf2e947079bdb3d295f8adcc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d9c218a18841759d1e510e17b5a0c5",
            "max": 5174,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9d553955334493ea4195eb3c8c9b0aa",
            "value": 5174
          }
        },
        "284409e6b77a40288113ac429d473871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d8bc70d0c6743cf8f201056a715892a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fd38cafe0c584ed082bc6874995fbd24",
            "value": "â€‡5.17k/5.17kâ€‡[00:00&lt;00:00,â€‡151kB/s]"
          }
        },
        "297410d3d2a04220ab58720ce90e3167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5249ca67ac3644ab850e8de36a3f57ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0d024eb0fde4e5fb929905f64532b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57d9c218a18841759d1e510e17b5a0c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d553955334493ea4195eb3c8c9b0aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d8bc70d0c6743cf8f201056a715892a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd38cafe0c584ed082bc6874995fbd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b05ce756ca0d4ecb8582fd1314e6b56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_197d95e8796f40eda244810e9d2a0cb3",
              "IPY_MODEL_3ad32c4b41e74d74ad2072c05f88474e",
              "IPY_MODEL_edde8e3d9acf45ca81e87c042a1187ae"
            ],
            "layout": "IPY_MODEL_93e55e3affb84fe9a91e0eac55c3335c"
          }
        },
        "197d95e8796f40eda244810e9d2a0cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe77c33e52b445a8a50ae6cb9f817e15",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a1c1c6fe5eaf4a3e8f3820d543fa5cd4",
            "value": "100%"
          }
        },
        "3ad32c4b41e74d74ad2072c05f88474e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6820fcd29a9b45e8877577a159ce72d7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b4753e86bad4cfca8a31ac6702e4afc",
            "value": 1
          }
        },
        "edde8e3d9acf45ca81e87c042a1187ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f3a88eb8434b22974333fdddcea1af",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9104b7b110fd496d9ad83260d2cce712",
            "value": "â€‡1/1â€‡[00:01&lt;00:00,â€‡â€‡1.34s/it]"
          }
        },
        "93e55e3affb84fe9a91e0eac55c3335c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe77c33e52b445a8a50ae6cb9f817e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c1c6fe5eaf4a3e8f3820d543fa5cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6820fcd29a9b45e8877577a159ce72d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b4753e86bad4cfca8a31ac6702e4afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76f3a88eb8434b22974333fdddcea1af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9104b7b110fd496d9ad83260d2cce712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2850ba6a3d2842e99bd72b1c98a06db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93c15c6d83be432095649c46800701d7",
              "IPY_MODEL_1fd8f8e7b1b148a193e8927065c55292",
              "IPY_MODEL_bab9b4617ebb4e85ba9ea819d78aafc9"
            ],
            "layout": "IPY_MODEL_d4c8f9f078bd4f66826d6aaf6d0851e1"
          }
        },
        "93c15c6d83be432095649c46800701d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bcb54d1d37a4b6da1a030237a687b40",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d603ded7253f40ebbd35c836c0b6793a",
            "value": "tokenizer.json:â€‡"
          }
        },
        "1fd8f8e7b1b148a193e8927065c55292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbfe03afe9eb440198833b709e25299e",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cdcf961f17b4728bd19ad790754278f",
            "value": 17209920
          }
        },
        "bab9b4617ebb4e85ba9ea819d78aafc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c1729d791924119a1cf76a33b6c3a79",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8c010685a9ba4493a8806e1967168760",
            "value": "â€‡32.0M/?â€‡[00:01&lt;00:00,â€‡26.9MB/s]"
          }
        },
        "d4c8f9f078bd4f66826d6aaf6d0851e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bcb54d1d37a4b6da1a030237a687b40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d603ded7253f40ebbd35c836c0b6793a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbfe03afe9eb440198833b709e25299e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cdcf961f17b4728bd19ad790754278f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c1729d791924119a1cf76a33b6c3a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c010685a9ba4493a8806e1967168760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
